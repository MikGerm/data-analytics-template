## Clean "Scraping" Data
import pandas as pd
import os

# Change to correct working directory
os.chdir("/Users/michaelgerardy/Documents/Data Wrangling Project")

# List of file paths
file_paths = [
    "Educational_Attainment2018.csv",
    "Educational_Attainment2019.csv",
    "Educational_Attainment2020.csv",
    "Educational_Attainment2021.csv",
    "Educational_Attainment2022.csv"
]

# Combined DataFrame
combined_df = pd.DataFrame()

# Read and combine all files
for file in file_paths:
    if os.path.exists(file):
        df = pd.read_csv(file)
        year = file.split("Attainment")[1].split(".")[0]  # Extract year
        df['Year'] = year  # Add year column
        combined_df = pd.concat([combined_df, df], ignore_index=True)
        print(f"Loaded {file}")
    else:
        print(f"File not found: {file}")

# Save the combined file
output_file = "Educational_Attainment_Combined.csv"
combined_df.to_csv(output_file, index=False)
print(f"Combined data saved to {output_file}")

## Clean Downloaded Data

# List of file paths
file_paths = [
    "HoustonLargestPD.csv",
    "ChicagoLargestPD.csv",
    "NewYorkLargestPD.csv",
    "PhoenixLargestPD.csv",
    "LosAngelesLargestPD.csv"
]

# Load the datasets into DataFrames
dataframes = {}
for file in file_paths:
    if os.path.exists(file):
        df = pd.read_csv(file)
        dataframes[file.split(".")[0]] = df
        print(f"Loaded {file}")
    else:
        print(f"File not found: {file}")

import pandas as pd
import re

# Load the downloaded crime data
crime_file = "LargestPD_Combined.csv"
crime_df = pd.read_csv(crime_file)

print("\nLoaded Crime Data Sample:")
print(crime_df.head())

# Extract 'city' names from 'series' column if 'city' is missing
if "city" not in crime_df.columns and "series" in crime_df.columns:
    crime_df["city"] = crime_df["series"].str.extract(r"(houston|chicago|phoenix|new york|los angeles|california)", flags=re.IGNORECASE)
    crime_df["city"] = crime_df["city"].str.lower().str.strip()

# Extract 'year' from column names containing years
year_columns = crime_df.filter(regex="\\d{4}").columns

# Melt the DataFrame to long format for year and value
crime_df = crime_df.melt(id_vars=["series", "city"], value_vars=year_columns, 
                         var_name="year", value_name="value")

# Drop rows with NaN in 'year' before extracting integers
crime_df = crime_df.dropna(subset=["year"])  # Remove NaN rows in 'year'

# Ensure 'year' contains only integers
crime_df["year"] = crime_df["year"].astype(str).str.extract(r"(\d{4})")  # Extract year
crime_df = crime_df.dropna(subset=["year"])  # Drop rows where extraction failed
crime_df["year"] = crime_df["year"].astype(int)  # Convert year to integer

# Drop rows where 'city' or 'value' are missing
crime_df = crime_df.dropna(subset=["city", "value"])

# Ensure 'value' is numeric
crime_df["value"] = crime_df["value"].astype(float)

# Keep relevant columns
crime_df = crime_df[["city", "year", "value"]]

# Display cleaned data
print("\nCleaned Crime Data Sample:")
print(crime_df.head())

# Save cleaned data
crime_df.to_csv("Cleaned_Crime_Data.csv", index=False)
print("Cleaned Crime Data saved to 'Cleaned_Crime_Data.csv'.")

## Merge Data with Graphs

# Load Crime Data
crime_file = "Cleaned_Crime_Data.csv"  # Replace with your path
crime_df_cleaned = pd.read_csv(crime_file)

# Ensure 'value' is numeric
crime_df_cleaned['value'] = pd.to_numeric(crime_df_cleaned['value'], errors='coerce')

# Drop any NaNs in year or value
crime_df_cleaned = crime_df_cleaned.dropna(subset=['year', 'value'])

# Confirm data
print("\nCleaned Crime Data Sample:")
print(crime_df_cleaned.head())

# Load Crime Data
crime_file = "Cleaned_Crime_Data.csv"  # Replace with your path
crime_df_cleaned = pd.read_csv(crime_file)

# Ensure 'value' is numeric
crime_df_cleaned['value'] = pd.to_numeric(crime_df_cleaned['value'], errors='coerce')

# Drop any NaNs in year or value
crime_df_cleaned = crime_df_cleaned.dropna(subset=['year', 'value'])

# Confirm data
print("\nCleaned Crime Data Sample:")
print(crime_df_cleaned.head())

# Convert 'value' column to string first, then clean it
edu_df_cleaned['value'] = edu_df_cleaned['value'].astype(str).str.replace(',', '', regex=True)

# Convert the cleaned 'value' column to numeric
edu_df_cleaned['value'] = pd.to_numeric(edu_df_cleaned['value'], errors='coerce')

# Drop rows with NaN values in 'year' and 'value'
edu_df_cleaned = edu_df_cleaned.dropna(subset=['year', 'value'])

# Group by year and sum the values
edu_summary = edu_df_cleaned.groupby('year')['value'].sum().reset_index()

# Plot Educational Data Trends
plt.figure(figsize=(10, 6))
plt.plot(edu_summary['year'], edu_summary['value'], marker='o', color='blue')
plt.title('Educational Data Trends Over Time')
plt.xlabel('Year')
plt.ylabel('Total Educational Values')
plt.grid(True)
plt.show()

# Pivot Educational Data to compare cities across years
edu_pivot = edu_df_cleaned.pivot_table(index='year', columns='city', values='value', aggfunc='sum')

# Plot Stacked Bar Chart for Educational Data
edu_pivot.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='viridis')
plt.title('Educational Data by City Over Time')
plt.xlabel('Year')
plt.ylabel('Total Educational Values')
plt.legend(title='City')
plt.show()
